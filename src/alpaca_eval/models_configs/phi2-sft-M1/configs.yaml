# ---
# phi-2-sft:
#   prompt_template: "phi-2-sft/prompt.txt"
#   fn_completions: "huggingface_local_completions"
#   completions_kwargs:
#     model_name: "lxuechen/phi-2-sft"
#     model_kwargs:
#       torch_dtype: 'bfloat16'
#       trust_remote_code: True
#     max_new_tokens: 1024
#     temperature: 0.7
#     top_p: 1.0
#     do_sample: True
#   pretty_name: "Phi-2 SFT"
#   link: "https://huggingface.co/lxuechen/phi-2-sft"

 phi2-sft-M1: # this should be the same as the name as the current directory
  prompt_template: "phi2-sft-M1/prompt.txt" # what prompt should be used for this model
  fn_completions: "huggingface_local_completions" # what function should be used to generate completions. See `src/alpaca_eval/decoders` for options
  completions_kwargs: # parameters to the completion function
    model_name: "Dudep/phi2-sft-M1"
    model_kwargs:
      torch_dtype: 'bfloat16'
      trust_remote_code: True
    max_new_tokens: 1024
    temperature: 0.7
    top_p: 1.0
    do_sample: True
  pretty_name: "phi2-sft-M1" # name in the leaderboard
  link: "https://huggingface.co/Dudep/phi2-sft-M1" # link to the model's repo/information in the leaderboard

